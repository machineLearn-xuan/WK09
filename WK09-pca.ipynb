{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why PCA ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/data_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from data_utils import PCA, StandardScaler, KMeansClustering, object_from_json_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PENGUIN_URL = \"https://raw.githubusercontent.com/PSAM-5020-2025S-A/5020-utils/refs/heads/main/datasets/json/penguins.json\"\n",
    "penguin_data = object_from_json_url(PENGUIN_URL)\n",
    "\n",
    "penguins_df = pd.DataFrame.from_records(penguin_data)\n",
    "penguins_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penguin Example\n",
    "\n",
    "Explore the penguin data.\n",
    "\n",
    "Let's encode the species column into integers.\n",
    "It's a simple encoding, so we can just do it manually using a function and the `DataFrame.apply()` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = list(penguins_df[\"species\"].unique())\n",
    "\n",
    "def species_to_label(s):\n",
    "  return species.index(s)\n",
    "\n",
    "penguins_df[\"label\"] = penguins_df[\"species\"].apply(species_to_label)\n",
    "\n",
    "display(penguins_df)\n",
    "penguins_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Scale data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariances\n",
    "\n",
    "If we're trying to get some insight into our data, we can look at covariance tables and some plots.\n",
    "\n",
    "Now that we have scaled data we can look at covariance tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Look at covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 2 or 3 most related features with idxmax()\n",
    "p_cov = penguins_scaled_df.cov()\n",
    "p_cov[p_cov == p_cov.max(axis=1)] = 0\n",
    "\n",
    "display(p_cov)\n",
    "p_cov.abs().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Separate features from the scaled full DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Data\n",
    "\n",
    "We can look at plots of the most correlated features, and of all of the possible pairs of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOP FEATURES\")\n",
    "# TOP CORRELATED FEATURES\n",
    "\n",
    "# TODO: Add the 2 most correlated features here\n",
    "top_features = []\n",
    "\n",
    "for i,cx in enumerate(top_features):\n",
    "  for j,cy in enumerate(top_features):\n",
    "    if j > i:\n",
    "      plt.scatter(penguins_features_df[cx], penguins_features_df[cy], c=penguins_df[\"label\"])\n",
    "      plt.xlabel(cx)\n",
    "      plt.ylabel(cy)\n",
    "      plt.show()\n",
    "\n",
    "print(\"ALL FEATURES\")\n",
    "# ALL FEATURES\n",
    "for i,cx in enumerate(penguins_features_df.columns):\n",
    "  for j,cy in enumerate(penguins_features_df.columns):\n",
    "    if j > i:\n",
    "      plt.scatter(penguins_features_df[cx], penguins_features_df[cy], c=penguins_df[\"label\"])\n",
    "      plt.xlabel(cx)\n",
    "      plt.ylabel(cy)\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "The plots tell us a lot, but information is spread through many images.\n",
    "\n",
    "The top-correlated features actually make it hard to see the separation between $2$ of the species of penguins.\n",
    "\n",
    "We can try to simplify how we visualize this data by performing `PCA` and combining some of the original features into _principal components_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create PCA with 3 components\n",
    "\n",
    "# TODO: fit+transform\n",
    "\n",
    "# TODO: look at explained variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariances Again\n",
    "\n",
    "Can look at covariance table of the `PCA` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Look at covariance of PCA data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm... the covariances of the `PCA` data look strange...\n",
    "\n",
    "But, that's actually what's expected.\n",
    "\n",
    "`PCA` separates our data into new features that are combinations of the previous features, but that are themselves not related to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_column_names = penguins_pca_df.columns\n",
    "\n",
    "# First 2 PCs\n",
    "plt.scatter(penguins_pca_df[pca_column_names[0]], penguins_pca_df[pca_column_names[1]], c=penguins_df[\"label\"])\n",
    "plt.xlabel(pca_column_names[0])\n",
    "plt.ylabel(pca_column_names[1])\n",
    "plt.title(\"2 PCs\")\n",
    "plt.show()\n",
    "\n",
    "# First 3 PCs\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter(penguins_pca_df[pca_column_names[0]],\n",
    "           penguins_pca_df[pca_column_names[1]],\n",
    "           penguins_pca_df[pca_column_names[2]],\n",
    "           c=penguins_df[\"label\"])\n",
    "ax.set_xlabel(pca_column_names[0])\n",
    "ax.set_ylabel(pca_column_names[1])\n",
    "ax.set_zlabel(pca_column_names[2])\n",
    "ax.set_title(\"3 PCs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it has combined some of the features, we can still see a lot of information from our original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "\n",
    "I wonder what clustering would do..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguin_clusterer = KMeansClustering(n_clusters=6)\n",
    "penguin_clusters = penguin_clusterer.fit_predict(penguins_pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 3 PCs\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter(penguins_pca_df[pca_column_names[0]],\n",
    "           penguins_pca_df[pca_column_names[1]],\n",
    "           penguins_pca_df[pca_column_names[2]],\n",
    "           c=penguin_clusters[\"clusters\"])\n",
    "ax.set_xlabel(pca_column_names[0])\n",
    "ax.set_ylabel(pca_column_names[1])\n",
    "ax.set_zlabel(pca_column_names[2])\n",
    "ax.set_title(\"3 PCs\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "9103",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
