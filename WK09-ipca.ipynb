{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse PCA\n",
    "\n",
    "Let's explore the \"latent space\" of `PCA`.\n",
    "\n",
    "We can think of `PCA` as a kind of factorization or decomposition of our original images into $2$ values each: one that is a new reduced set of features, called the principal components, and the other is a set of common features extracted from all images.\n",
    "\n",
    "So, each image $I_i$ can now be represented as a multiplication $I_i = PC_i \\cdot V$, where $PC_i$ are the principal components of $I_i$, and $V$ are the common values extract from all images.\n",
    "\n",
    "Let's look at an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First we download some libraries and data, and import helpers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/data_utils.py\n",
    "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/image_utils.py\n",
    "\n",
    "!wget -qO- https://github.com/PSAM-5020-2025S-A/5020-utils/releases/latest/download/att-faces.tar.gz | tar xz\n",
    "!wget -qO- https://github.com/PSAM-5020-2025S-A/5020-utils/releases/latest/download/metfaces.tar.gz | tar xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import PIL.Image as PImage\n",
    "\n",
    "from numpy.random import normal as np_normal, randint\n",
    "from os import listdir, path\n",
    "\n",
    "from data_utils import PCA, StandardScaler\n",
    "from image_utils import get_pixels, make_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "This is the `AT&T` faces dataset with $400$ images that have been cropped and somewhat aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_width = 92\n",
    "\n",
    "# lists for keeping track of image pixel lists, subject numeric id and subject label\n",
    "face_pixels = []\n",
    "\n",
    "# 40 directories\n",
    "for l in range(1, 41):\n",
    "  # 10 images per directory\n",
    "  for i in range(1, 11):\n",
    "    mimg = PImage.open(f\"./data/image/att-faces/s{l}/{i}.pgm\")\n",
    "    img_width = mimg.size[0]\n",
    "    face_pixels.append(get_pixels(mimg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Processing\n",
    "\n",
    "Get some info about our data, and run `PCA` on all images/rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset shape\n",
    "print(len(face_pixels), \" X \", len(face_pixels[0]))\n",
    "\n",
    "# display first image\n",
    "display(make_image(face_pixels[0], width=img_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA and Resulting Transformation\n",
    "\n",
    "We can see how much information from the original data was kept by our `PCA` transformation, and what common components were extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run pca and get first 256 PCs\n",
    "pca = PCA(n_components=256)\n",
    "faces_df = pca.fit_transform(face_pixels)\n",
    "\n",
    "print(\"explained variance:\", pca.explained_variance())\n",
    "\n",
    "# shape of the common values V\n",
    "print(\"common values V\", pca.components.shape)\n",
    "\n",
    "# shape of resulting dataframe\n",
    "print(\"Resulting DataFrame:\", faces_df.shape[0], \"rows and\", faces_df.shape[1], \"features (principal components)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The common extracted values are themselves $256$ images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct\n",
    "\n",
    "We now have each of our images represented with $256$ values. They've been compressed from $10\\text{,}304$ pixels to $256$ components. Since we're only using a portion of the total number of components, we won't be able to fully recuperate the original images, but we should be able to get something pretty close since we're keeping more than $90\\%$ of the information from the original images.\n",
    "\n",
    "Instead of breaking our images down into principal components and common factors, we also have an error $e_i$:\n",
    "\n",
    "$I_i = PC_i \\cdot V + e_i$\n",
    "\n",
    "But, we can still use $PC_i \\cdot V$ to reconstruct our original images.\n",
    "\n",
    "We can transform the $256$ values back into $10\\text{,}304$ pixels using the `inverse_transform()` function of our `PCA` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction: transforms the data from PCA space into pixel space\n",
    "pca_pixels = pca.inverse_transform(faces_df)\n",
    "\n",
    "for i in range(4):\n",
    "  idx = randint(0, len(face_pixels))\n",
    "  display(make_image(face_pixels[idx], width=img_width))\n",
    "  display(make_image(pca_pixels.loc[idx], width=img_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Factors\n",
    "\n",
    "These are the common values extracted from the dataset. It's the value $V$ from the equation:\n",
    "\n",
    "$I_i = PC_i \\cdot V + e_i$\n",
    "\n",
    "All reconstructions are built from linear combinations of these features that are common between all images.\n",
    "\n",
    "There are $256$ of them, one for each $PC$ component extracted, but let's only look at the first $4$, since those are the most important/common shapes present in our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp in pca.components[:4]:\n",
    "  minVal = comp.min()\n",
    "  maxVal = comp.max()\n",
    "  # manually mapping to [0, 255]\n",
    "  pxs01 = 255 * (comp - minVal) / (maxVal - minVal)\n",
    "  display(make_image(pxs01, width=img_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the PC values\n",
    "\n",
    "We have a new dataset that is made up of $256$ PC features.\n",
    "\n",
    "The range of values for the $PC$ feature are very different. The first few components of each image tend to have values that are a lot larger than the last components. This is expected and part of the process of making more common features be turned into more important components. The components are ordered by the amount of variance they explain.\n",
    "\n",
    "If we were to use the PC features to train a classifier, we would keep them unscaled, but we can scale them as part of our current exploratory analysis.\n",
    "\n",
    "This helps understand the distribution of their values and will also help us pick sensible random values for them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at distributions of un-normalized PC values\n",
    "faces_df.describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the PCs\n",
    "pca_scaler = StandardScaler()\n",
    "faces_pca_std_df = pca_scaler.fit_transform(faces_df)\n",
    "\n",
    "display(faces_pca_std_df)\n",
    "display(faces_pca_std_df.describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot distribution of PCs\n",
    "\n",
    "This is exploratory.\n",
    "\n",
    "For each image, we'll plot its first $32$ features.\n",
    "\n",
    "In the same plot, highlight the values for the first $4$ images in our dataset.\n",
    "\n",
    "All the red dots are the PC values that are needed to reconstruct the first image, shown in relation to the distribution of all the values of the PCs of all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pcs = 32\n",
    "num_faces = 4\n",
    "cmap = plt.get_cmap(\"Set1\")\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "for i in range(0,num_pcs):\n",
    "  plt.scatter(faces_pca_std_df[f\"PC{i}\"], faces_pca_std_df.shape[0] * [i], alpha=0.25, color='#2280fa')\n",
    "\n",
    "\n",
    "for i in range(num_faces):\n",
    "  pcs = faces_pca_std_df.iloc[i].values[:num_pcs]\n",
    "  mcolor = cmap(i/num_faces)\n",
    "  plt.scatter(pcs, range(num_pcs), c=num_pcs*[mcolor], label=f\"Image {i}\")\n",
    "\n",
    "plt.xlabel(\"Normalized Value\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Average Face\n",
    "\n",
    "Our simplified math representation of the `PCA` transformation shows that we can get face images $I_i$ by multiplying $256$ PC values by $256$ images (the $V$ components):\n",
    "\n",
    "$PC_i \\cdot V \\rightarrow I_i$\n",
    "\n",
    "So far, the PC values we've been using to reconstruct images were coming from the original dataset, but the $V$ values should have enough information about faces that if we multiply any set of $256$ values by $V$ it should give us a face.\n",
    "\n",
    "Let's start by looking at what happens if we construct an image from the average value of all of the PCs.\n",
    "\n",
    "This could be the `DataFrame` we get by computing `mean()` for all PCs in their original ranges: `faces_df.mean()`, but since those features were themselves normalized, they would all have an average value of $0$.\n",
    "\n",
    "This means we can re-construct the most average face of our dataset by `inverse_transforming()` a list of $256$ zeroes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_std_df = pd.DataFrame([pca.n_components * [0]], columns=faces_df.columns)\n",
    "avg_pca_df = pca_scaler.inverse_transform(avg_std_df)\n",
    "\n",
    "avg_img = pca.inverse_transform(avg_pca_df)\n",
    "display(make_image(avg_img.loc[0], width=img_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Faces\n",
    "\n",
    "We can also reconstruct faces from $256$ random values.\n",
    "\n",
    "We could pick them completely random, but let's use normal distributions to make sure we don't go too far from the average value of any particular component.\n",
    "\n",
    "We'll create a `DataFrame` that has $4$ faces represented in scaled `PCA` space.\n",
    "\n",
    "We'll then un-scale and un-PCA these values to create $4$ random faces that are very unlikely to be in our original dataset, but that are re-created based on real data features that were extracted in the form of principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ifaces = 4\n",
    "\n",
    "rand_std_pcs = pd.DataFrame(np_normal(size=[num_ifaces, pca.n_components], scale=0.666), columns=faces_df.columns)\n",
    "rand_pcs = pca_scaler.inverse_transform(rand_std_pcs)\n",
    "rand_img = pca.inverse_transform(rand_pcs)\n",
    "\n",
    "for i in range(num_ifaces):\n",
    "  display(make_image(rand_img.loc[i], width=img_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Dataset\n",
    "\n",
    "The re-constructed random faces look like faces, but the `AT&T` images are not very diverse ($40$ people), and, since part of the original experiment with these faces was to see how robust this method was to minor variations in face positioning, the faces aren't very well aligned.\n",
    "\n",
    "We can see that very clearly in the reconstructions. It's like there are a bunch ($256$ to be exact) faces being superimposed, but they're not aligned.\n",
    "\n",
    "Here's a dataset that has $1336$ unique faces that have been better aligned and scaled.\n",
    "\n",
    "Run this cell and then repeat the process starting from the _Start Processing_ cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 256\n",
    "MET_PATH = f\"./data/image/metfaces/{img_width}\"\n",
    "\n",
    "face_pixels = []\n",
    "\n",
    "for f in sorted([f for f in listdir(MET_PATH) if f.endswith(\".jpg\")]):\n",
    "  mimg = PImage.open(path.join(MET_PATH, f)).convert(\"L\")\n",
    "  face_pixels.append(list(mimg.getdata()))\n",
    "\n",
    "display(mimg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "9103",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
